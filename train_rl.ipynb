{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-22T21:31:27.668748Z",
     "start_time": "2025-02-22T21:31:25.907304Z"
    }
   },
   "source": [
    "\n",
    "from board3 import Board3, sqr_distance, empty_cells, tod_cells\n",
    "from controller3 import ActionController, MW_CELLS\n",
    "import time\n",
    "from heapq import heappush, heappop\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions.categorical import Categorical\n",
    "from collections import Counter, deque\n",
    "from mcts import search\n",
    "from nnl import gather_history\n",
    "\n",
    "import torch.multiprocessing as tmp"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T21:31:27.678404Z",
     "start_time": "2025-02-22T21:31:27.673062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_emb(board: Board3):\n",
    "\n",
    "    py, px = board.get_player_position()\n",
    "    ey, ex = board.get_enemy_position()\n",
    "    ty, tx = board.get_todd_position()\n",
    "\n",
    "    mws = [0] * 16\n",
    "\n",
    "    for (y, x) in board.mw:\n",
    "        mws[y * 4 + x] = 1\n",
    "\n",
    "    pe = torch.Tensor([[py, px, ey, ex, ty, tx]]) / 3\n",
    "    mwe = torch.Tensor([mws])\n",
    "\n",
    "    return torch.cat([pe, mwe], dim=1)\n",
    "\n",
    "\n",
    "def emb_mem(mem, nc=2):\n",
    "    fe = []\n",
    "    for b, a in mem:\n",
    "        e1 = to_emb(b)\n",
    "        e2 = nn.functional.one_hot(torch.LongTensor([a]), num_classes=nc)\n",
    "        fe.append(torch.cat([e1, e2], dim=1))\n",
    "\n",
    "    return torch.cat(fe, dim=0).unsqueeze(0)"
   ],
   "id": "689d3375719d645b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T21:31:27.773555Z",
     "start_time": "2025-02-22T21:31:27.767873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pos_encode(max_len, d_model, dtype=torch.float32):\n",
    "    position = torch.arange(max_len).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "    pe = torch.zeros(max_len, d_model, dtype=dtype)\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe\n",
    "\n",
    "\n",
    "class FP(nn.Module):\n",
    "    def __init__(self, n_dim, a_space, m_space, e_dim=384, ff_dim=1024, n_layers=4, n_heads=12, max_len=15):\n",
    "        super(FP, self).__init__()\n",
    "\n",
    "        self.fl = nn.Sequential(\n",
    "            nn.Linear(n_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, e_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "\n",
    "        self.fh = nn.Sequential(\n",
    "            nn.Linear(m_space, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, e_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "\n",
    "        self.dec_l = nn.TransformerDecoderLayer(d_model=e_dim, nhead=n_heads, dim_feedforward=ff_dim, batch_first=True)\n",
    "        self.dec = nn.TransformerDecoder(self.dec_l, num_layers=n_layers)\n",
    "\n",
    "        self.pe = pos_encode(max_len, e_dim)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(e_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, a_space),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        self.fv = nn.Sequential(\n",
    "            nn.Linear(e_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        nx = self.fl(x)\n",
    "        nh = self.fh(h) + self.pe[:h.shape[1], :].unsqueeze(0).to(h.device)\n",
    "        hidden = self.dec(nx.unsqueeze(1), nh).mean(dim=1)\n",
    "        return self.fc(hidden), self.fv(hidden)\n"
   ],
   "id": "a4afaa8ee610c065",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T21:31:27.821080Z",
     "start_time": "2025-02-22T21:31:27.811110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class NNT:\n",
    "\n",
    "    def __init__(self, board, player, m1, m2):\n",
    "        self.board = board\n",
    "        self.controller = ActionController(board)\n",
    "        self.children = None\n",
    "        self.player = player\n",
    "        self.action = None\n",
    "        self.prob = 0\n",
    "        self.value = 0\n",
    "        self.n = 0\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "        pass\n",
    "\n",
    "\n",
    "    def get_winner(self):\n",
    "        if self.controller.is_win():\n",
    "            return 1\n",
    "        if self.controller.is_lose():\n",
    "            return -1\n",
    "        if self.controller.is_block():\n",
    "            return -1\n",
    "\n",
    "        return None\n",
    "\n",
    "    def search(self, fp):\n",
    "\n",
    "        winner = self.get_winner()\n",
    "        if winner is not None:\n",
    "            self.n += 1\n",
    "            self.value = -winner\n",
    "            return self.value\n",
    "\n",
    "\n",
    "        if self.children is None:\n",
    "            self.expand(fp)\n",
    "\n",
    "            return -self.value\n",
    "\n",
    "        cs = sum([x.n for x in self.children])\n",
    "        sv = max(self.children, key=lambda x: x.value + 0.5 * x.prob * (math.sqrt(cs ) / (x.n + 1)))\n",
    "        res = sv.search(fp)\n",
    "        self.value = (self.value * self.n + res) / (self.n + 1)\n",
    "        self.n += 1\n",
    "\n",
    "        return -res\n",
    "\n",
    "    def expand(self, fp):\n",
    "        self.children = []\n",
    "\n",
    "        if self.player == 1:\n",
    "            m = self.m1 + 0\n",
    "        else:\n",
    "            m = self.m2 + 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            o, v = fp(to_emb(self.board), m)\n",
    "\n",
    "        vs = []\n",
    "        for p in self.controller.get_available_moves():\n",
    "            b = self.board.copy()\n",
    "            ActionController(b).execute_action(p)\n",
    "            b.step(500)\n",
    "\n",
    "            if self.player == 1:\n",
    "                m1 = torch.cat([self.m1[:, 1:, :], emb_mem([(b, p)], ActionController.get_action_space())], dim=1)\n",
    "                m2 = self.m2\n",
    "            else:\n",
    "                m1 = self.m1\n",
    "                m2 = torch.cat([self.m2[:, 1:, :], emb_mem([(b, p)], ActionController.get_action_space())], dim=1)\n",
    "\n",
    "            nt = NNT(b, -self.player, m1, m2)\n",
    "            nt.action = p\n",
    "            nt.prob = o[:, p].exp().item()\n",
    "            nt.value = 0\n",
    "\n",
    "            if nt.controller.is_win():\n",
    "                nt.value = 1\n",
    "            elif nt.controller.is_lose():\n",
    "                nt.value = -1\n",
    "            elif nt.controller.is_block():\n",
    "                nt.value = -1\n",
    "\n",
    "            nt.n = 1\n",
    "            vs.append(nt.prob)\n",
    "            b.swap_enemy()\n",
    "            self.children.append(nt)\n",
    "\n",
    "        self.value = v.item()\n",
    "        self.n = len(vs)\n",
    "\n",
    "    def get_policy(self):\n",
    "        p = [0] * ActionController.get_action_space()\n",
    "        for x in self.children:\n",
    "            p[x.action] = x.n\n",
    "\n",
    "        return torch.Tensor(p) / sum(p)\n"
   ],
   "id": "3407143a85b13a76",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T21:52:29.011290Z",
     "start_time": "2025-02-22T21:52:28.992664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def run_episode(fp, mem_length = 10):\n",
    "    fp.eval()\n",
    "    b = Board3(walk_time=200)\n",
    "\n",
    "    y1 = emb_mem([(b, 0)] * mem_length, ActionController.get_action_space())\n",
    "    b.swap_enemy()\n",
    "    y2 = emb_mem([(b, 0)] * mem_length, ActionController.get_action_space())\n",
    "    b.swap_enemy()\n",
    "\n",
    "    nt = NNT(b, 1, y1, y2)\n",
    "\n",
    "    h = []\n",
    "\n",
    "    for _ in range(50):\n",
    "        for _ in range(50):\n",
    "            nt.search(fp)\n",
    "\n",
    "        mt = max(nt.children, key=lambda x: x.n)\n",
    "        nb = mt.board.copy()\n",
    "        nb.swap_enemy()\n",
    "\n",
    "        if nt.player == 1:\n",
    "            h.append((to_emb(nb), nt.m1, nt.get_policy()))\n",
    "        else:\n",
    "            h.append((to_emb(nb), nt.m2, nt.get_policy()))\n",
    "\n",
    "        act = ActionController(nb)\n",
    "\n",
    "        if act.is_win():\n",
    "            r = reversed([1 if i % 2 == 0 else -1 for i in range(len(h))])\n",
    "            return [(x, y, z, v) for (x, y, z), v in zip(h, r)]\n",
    "        elif act.is_lose():\n",
    "            r = reversed([-1 if i % 2 == 0 else 1 for i in range(len(h))])\n",
    "            return [(x, y, z, v) for (x, y, z), v in zip(h, r)]\n",
    "        elif act.is_block():\n",
    "            r = reversed([-1 if i % 2 == 0 else 0 for i in range(len(h))])\n",
    "            return [(x, y, z, v) for (x, y, z), v in zip(h, r)]\n",
    "\n",
    "        nt = mt\n",
    "\n",
    "    return [(x, y, z, 0) for x, y, z in h]\n",
    "\n",
    "\n",
    "def train_nn(data):\n",
    "    b, m, p, r = list(zip(*data))\n",
    "    dataset = TensorDataset(torch.cat(b, dim=0), torch.cat(m, dim=0), torch.stack(p), torch.Tensor(r))\n",
    "    nf = nfp()\n",
    "    # nf.load_state_dict(torch.load('models/fp.pth', map_location=torch.device('cpu'), weights_only=True), strict=False)\n",
    "    epochs = 5\n",
    "    optimizer = optim.AdamW(nf.parameters(), lr=0.001)\n",
    "    crit1 = nn.CrossEntropyLoss()\n",
    "    crit2 = nn.MSELoss()\n",
    "\n",
    "    lh = []\n",
    "    for _ in range(epochs):\n",
    "        el = []\n",
    "        for b, m, p, r in DataLoader(dataset, batch_size=64, shuffle=True):\n",
    "            optimizer.zero_grad()\n",
    "            o, v = nf(b, m)\n",
    "            l1 = crit1(o, p)\n",
    "            l2 = crit2(v.squeeze(1), r)\n",
    "            l = l1 + l2\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            el.append(l.item())\n",
    "        lh.append(sum(el) / len(el))\n",
    "\n",
    "\n",
    "    # plt.plot(lh)\n",
    "    # plt.show()\n",
    "    return nf\n",
    "\n",
    "\n",
    "def run_battle(fp, nf, mem_length = 10):\n",
    "\n",
    "    fp.eval()\n",
    "    nf.eval()\n",
    "\n",
    "    b = Board3(walk_time=200)\n",
    "\n",
    "    y1 = emb_mem([(b, 0)] * mem_length, ActionController.get_action_space())\n",
    "    b.swap_enemy()\n",
    "    y2 = emb_mem([(b, 0)] * mem_length, ActionController.get_action_space())\n",
    "    b.swap_enemy()\n",
    "\n",
    "    act = ActionController(b)\n",
    "\n",
    "    for _ in range(50):\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            o, v = fp(to_emb(b), y1)\n",
    "            a1 = o.exp().argmax().item()\n",
    "            y1 = torch.cat([y1[:, 1:, :], emb_mem([(b, a1)], ActionController.get_action_space())], dim=1)\n",
    "        act.execute_action(a1)\n",
    "        b.step(500)\n",
    "\n",
    "        if act.is_win():\n",
    "            return 1\n",
    "        elif act.is_lose():\n",
    "            return -1\n",
    "        elif act.is_block():\n",
    "            return -1\n",
    "\n",
    "        b.swap_enemy()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            o, v = nf(to_emb(b), y2)\n",
    "            a2 = o.exp().argmax().item()\n",
    "            y2 = torch.cat([y2[:, 1:, :], emb_mem([(b, a2)], ActionController.get_action_space())], dim=1)\n",
    "\n",
    "        act.execute_action(a2)\n",
    "        b.step(500)\n",
    "\n",
    "        if act.is_win():\n",
    "            return -1\n",
    "        elif act.is_lose():\n",
    "            return 1\n",
    "        elif act.is_block():\n",
    "            return 1\n",
    "\n",
    "        b.swap_enemy()\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def eval_nn(fp, nf, n = 40):\n",
    "    w = 0\n",
    "    d = 0\n",
    "    l = 0\n",
    "    for _ in range(n):\n",
    "        r = run_battle(fp, nf)\n",
    "        if r == 1:\n",
    "            w += 1\n",
    "        elif r == 0:\n",
    "            d += 1\n",
    "        else:\n",
    "            l += 1\n",
    "\n",
    "    return w / n, d / n, l / n"
   ],
   "id": "61911aa5e21092de",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T21:52:29.717797Z",
     "start_time": "2025-02-22T21:52:29.713833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def nfp():\n",
    "    b = Board3(walk_time=200)\n",
    "    x = to_emb(b)\n",
    "    y = emb_mem([(b, 0)] * 2, ActionController.get_action_space())\n",
    "    return FP(x.shape[1], ActionController.get_action_space(), y.shape[-1])"
   ],
   "id": "b047bd3763b81fe8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-22T21:52:31.734213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fp = nfp()\n",
    "fp.load_state_dict(torch.load('models/fp.pth', map_location=torch.device('cpu'), weights_only=True), strict=False)\n",
    "fp.eval()\n",
    "\n",
    "\n",
    "hist = deque(maxlen=10000)\n",
    "\n",
    "for _ in tqdm(range(10)):\n",
    "\n",
    "    h = deque(maxlen=10000)\n",
    "    while len(h) < 100:\n",
    "        h += run_episode(fp)\n",
    "\n",
    "    nf = train_nn(h)\n",
    "\n",
    "    w, d, l = eval_nn(fp, nf)\n",
    "    print(w, d, l)\n",
    "    if w > 0.55:\n",
    "        print('Upgrade')\n",
    "        fp = nf\n"
   ],
   "id": "afa6891a727655df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b92f746bf1724e0c8f55d512647cf76d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "24d760639a46b49f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
